{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-17 23:59:41.856 [DEBUG] :: ai\n",
      "2024-04-17 23:59:43.491 [DEBUG] :: [\u001b[32msuccess\u001b[0m] Returned 18 search results for ai\n",
      "tweet id: 1780626667997659319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TweetDetail:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-17 23:59:45.017 [DEBUG] :: [\u001b[32m200\u001b[0m]\n",
      "2024-04-17 23:59:45.017 [DEBUG] :: /i/api/graphql/zXaXQgfyR4GxE21uwYQSyA/TweetDetail\n",
      "2024-04-17 23:59:45.018 [DEBUG] :: remaining: \u001b[35m148/150\u001b[0m requests\n",
      "2024-04-17 23:59:45.018 [DEBUG] :: reset:     \u001b[35m14.33\u001b[0m minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TweetDetail: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_20964\\2723020308.py:53: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  .assign(created_at=lambda x: pd.to_datetime(x[\"created_at\"]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-17 15:59:34+00:00</td>\n",
       "      <td>1780627171209257149</td>\n",
       "      <td>1656328215839776769</td>\n",
       "      <td>@NerisQueenAI Perfection every time 😍❤️</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'id_str': '1734980797755535360', 'name': 'Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-17 15:59:18+00:00</td>\n",
       "      <td>1780627102896963893</td>\n",
       "      <td>1663612280133795840</td>\n",
       "      <td>@NerisQueenAI You look so good Neris. You’re s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'id_str': '1734980797755535360', 'name': 'Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-17 15:59:15+00:00</td>\n",
       "      <td>1780627089953050798</td>\n",
       "      <td>1726640564064354304</td>\n",
       "      <td>@NerisQueenAI 💖💖💖😊😊🤩🤩❤️❤️😍😍😍💕💕🥰😘😘♥️♥️😘🥰🥰💕😍😍❤️💖...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'id_str': '1734980797755535360', 'name': 'Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-17 15:57:56+00:00</td>\n",
       "      <td>1780626757848379830</td>\n",
       "      <td>1663612280133795840</td>\n",
       "      <td>@NerisQueenAI You’re awesome. 💗💗🔥🔥💖💕💕 https://...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'id_str': '1734980797755535360', 'name': 'Ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at               id_str          user_id_str  \\\n",
       "0 2024-04-17 15:59:34+00:00  1780627171209257149  1656328215839776769   \n",
       "1 2024-04-17 15:59:18+00:00  1780627102896963893  1663612280133795840   \n",
       "2 2024-04-17 15:59:15+00:00  1780627089953050798  1726640564064354304   \n",
       "3 2024-04-17 15:57:56+00:00  1780626757848379830  1663612280133795840   \n",
       "\n",
       "                                           full_text  favorite_count urls  \\\n",
       "0            @NerisQueenAI Perfection every time 😍❤️               0   []   \n",
       "1  @NerisQueenAI You look so good Neris. You’re s...               0   []   \n",
       "2  @NerisQueenAI 💖💖💖😊😊🤩🤩❤️❤️😍😍😍💕💕🥰😘😘♥️♥️😘🥰🥰💕😍😍❤️💖...               0   []   \n",
       "3  @NerisQueenAI You’re awesome. 💗💗🔥🔥💖💕💕 https://...               0   []   \n",
       "\n",
       "  hashtags                                      user_mentions  \n",
       "0       []  [{'id_str': '1734980797755535360', 'name': 'Ne...  \n",
       "1       []  [{'id_str': '1734980797755535360', 'name': 'Ne...  \n",
       "2       []  [{'id_str': '1734980797755535360', 'name': 'Ne...  \n",
       "3       []  [{'id_str': '1734980797755535360', 'name': 'Ne...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from twitter.search import Search\n",
    "from twitter.scraper import Scraper\n",
    "import pandas as pd\n",
    "\n",
    "email, username, password = \"b10705052@ntu.edu.tw\", \"yehyouming\", \"Ym911216\"\n",
    "\n",
    "search = Search(email, username, password, save=False, debug=1)\n",
    "scraper = Scraper(email, username, password, debug=1, save=False)\n",
    "\n",
    "res = search.run(\n",
    "    limit=1,\n",
    "    retries=1,\n",
    "    queries=[{\"category\": \"Top\", \"query\": \"ai\"}],\n",
    ")\n",
    "\n",
    "# get the first tweet\n",
    "r = res[0][0]\n",
    "\n",
    "if r[\"content\"][\"itemContent\"][\"tweet_results\"][\"result\"][\"__typename\"] == \"Tweet\":\n",
    "    full_text = r[\"content\"][\"itemContent\"][\"tweet_results\"][\"result\"][\"legacy\"][\n",
    "        \"full_text\"\n",
    "    ]\n",
    "    rest_id = r[\"content\"][\"itemContent\"][\"tweet_results\"][\"result\"][\"rest_id\"]\n",
    "    print(\"tweet id:\", rest_id)\n",
    "\n",
    "    tweets_details = scraper.tweets_details([rest_id], count=100, limit=100)\n",
    "\n",
    "    df_tweets_details = (\n",
    "        pd.json_normalize(\n",
    "            tweets_details,\n",
    "            record_path=[\n",
    "                \"data\",\n",
    "                \"threaded_conversation_with_injections_v2\",\n",
    "                \"instructions\",\n",
    "            ],\n",
    "        )[\"entries\"]\n",
    "        .dropna()\n",
    "        .explode()\n",
    "        .apply(pd.Series)[\"content\"]\n",
    "        .apply(pd.Series)[\"items\"]\n",
    "        .dropna()\n",
    "        .explode()\n",
    "        .apply(pd.Series)[\"item\"]\n",
    "        .apply(pd.Series)[\"itemContent\"]\n",
    "        .apply(pd.Series)\n",
    "        .pipe(lambda df: df[df[\"__typename\"] != \"TimelineTimelineCursor\"])[\n",
    "            \"tweet_results\"\n",
    "        ]\n",
    "        .apply(pd.Series)[\"result\"]\n",
    "        .apply(pd.Series)\n",
    "        .pipe(lambda df: df[df[\"__typename\"] != \"TweetWithVisibilityResults\"])[\"legacy\"]\n",
    "        .apply(pd.Series)\n",
    "        .pipe(lambda x: pd.concat([x, x[\"entities\"].apply(pd.Series)], axis=1))\n",
    "        .assign(created_at=lambda x: pd.to_datetime(x[\"created_at\"]))\n",
    "        .sort_values(\"created_at\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "        .drop(\"entities\", axis=1)[\n",
    "            [\n",
    "                \"created_at\",\n",
    "                \"id_str\",\n",
    "                \"user_id_str\",\n",
    "                \"full_text\",\n",
    "                \"favorite_count\",\n",
    "                \"urls\",\n",
    "                \"hashtags\",\n",
    "                \"user_mentions\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "df_tweets_details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
